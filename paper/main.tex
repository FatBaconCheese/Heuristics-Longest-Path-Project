\documentclass[twocolumn,showpacs,%
  nofootinbib,aps,superscriptaddress,%
  eqsecnum,prd,notitlepage,showkeys,11pt]{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage[hidelinks,colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{titlesec}
\usepackage{minted}
\usepackage{authblk}
\usepackage[legalpaper, margin=1in]{geometry}
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

\begin{document}

\title{Heuristics in the Longest Simple Path Problem}
\author[1]{Justin J. Xie}
\author[2]{Bart Massey}
\author[2]{Cassaundra Smith}
\affil[1]{Institute for Computing in Research}
\affil[2]{Portland State University}
\date{}


\twocolumn[\begin{@twocolumnfalse}
\maketitle
\begin{abstract}
Finding the Longest Simple Path (LSP) in an unweighted undirected graph is an NP-Hard problem. We have explored the effectiveness of various heuristics for the LSP problem, and their potential for further use. In our exploration, we implemented heuristics inspired by well-known greedy techniques. Other heuristics utilized novel graph features to improve performance. We benchmarked the performance of these heuristics on accuracy, error, and speed on small random graphs. We found that these heuristics provided a considerable speed improvement to the na\"ive brute-force solution. We found that sparse graphs were the most difficult for our heuristics. This result supports other research indicating that sparse graphs continue to provide challenges for heuristics and approximation algorithms to solve.
\end{abstract}
\end{@twocolumnfalse}]  

\section{Introduction}

The Longest Simple Path (LSP) problem is a long-standing problem of both theoretical and practical interest. {\em briefly explain the problem}

Much work has been done on variations of the LSP problem. Solutions to the longest paths in directed, acyclic graphs and trees are the most commonly referenced and utilized solutions. In our research, we set out to explore the LSP problem in undirected unweighted connected graphs. The LSP problem is NP-hard: there is no existing solution or computer capable of finding the LSP of an arbitrary graph in polynomial time. As such, heuristic approximation might be an attractive alternative to searching for perfect solutions. In our research, we explored heuristics for this purpose.

Our main research contribution is the development and examination of high-level heuristics and principles of two different kinds: variations of the classic greedy approach, and heuristics involving constructing spanning trees from the graph in order to utilize Dijkstra's LSP algorithm for trees~\cite{?}. These heuristics classified a graph's vertices as "peripheral" and "central", using this classification along with other graph features to determine which edges to cut during tree construction.

We tried five heuristics that fall into one of the two categories mentioned above. We experimented with the implementation of these heuristics and obtained benchmark results that allow comparison to past and future explorations of the LSP problem. The data we gathered on these heuristics allowed us to gain some insight into sources of difficulty in LSP construction. We found that each heuristic had its own points of failure. The greedy algorithm failed to break ties; the graph pruning heuristic may not be cutting the most optimal edges. These issues can be further explored and possible remedies can be found for more efficient and accurate heuristics.

We found that when compared to past proposed greedy heuristics, our greedy heuristic showed similar behaviors when the number of edges in a graph was increased. It performed adequately in trees and denser graphs, where many solutions were available, but struggled with certain sparse graphs that only contained one or two possible longest simple paths. The graph pruning heuristics also showed promise for future use. On their own, they struggled to consistently cut the graph into a tree containing the longest simple path. 

Our research has shown that heuristics, although far faster than brute-force algorithms, often fail to account for the bigger picture. In our exploration of the LSP problem, the greedy and graph pruning/periphery heuristics that only registered and factored in data local to their ``current position'' in the graph required few calculations, making them faster. Longest simple paths, however, often require a view of the graph in its entirety in order to find the exact solution. Thus, heuristics that factor in all of the graph or make an extra calculation when deciding on a ``next vertex'' are the ones that outperformed in the accuracy category when compared to similar heuristics.

This is also the reason for the heuristics' improved ability to find longest paths on dense graphs in comparison to sparse graphs. Dense graphs give heuristics far more options for possible longest simple paths. As a result, even when the heuristics do not consider the entirety of the graph, the path they follow is more likely to be the LSP. In sparse graphs, there are often only one or two longest simple paths, where a single wrong turn in a heuristic's path will lead to an incorrect LSP. As has been confirmed by several other papers and their heuristics, the sparse graphs continue to be the more challenging aspect of implementing heuristics into the longest simple path problem.

\section{Background}

The longest simple path (LSP) in a graph is the longest possible path that originates at any vertex and traverses the graph without repeating vertices. The problem is an NP-Hard problem: there is no known algorithm capable of finding the LSP on an arbitrary graph in polynomial time. As the number of vertices and the size of the graph increases, any algorithm that guarantees an accurate solution hits an ``exponential wall'' where even the fastest and most optimized hardware struggle to efficiently identify the longest simple path in an efficient manner.

\section{Related Work} 
The longest simple path problem is a constantly revisited problem. While no general solution has been found, continual research into the problem has found polynomial-time solutions or even linear time solutions for many classes of graph.

One such class is the directed acyclic graph. The longest path of these graphs can be found in linear time by inverting each edge's weight and solving it as a shortest path problem using topological sort.~\cite{?}

Trees---undirected, acyclic graphs---are solvable in linear time using an algorithm by Dijkstra that we call the ``Dijkstra Dangle''. This algorithm finds two ``extremes" of a tree using two breadth first searches: the path between them is the LSP for the tree~\cite{club2002computing}.

Block graphs and weighted trees have been shown to have linear time solutions; Cacti graphs in $\mathcal{O}(n^2)$ time~\cite{uehara2004efficient, uehara2007computing}. Bipartite Permutation graphs, too, have an $\mathcal{O}(n)$ solution~\cite{uehara2007linear}. Interval graphs are solvable in $\mathcal{O}(n^4)$ time~\cite{ioannidou2009longest,  giannopoulou2015polynomial}, Circular-Arc graphs in $\mathcal{O}(n^4)$ time~\cite{mertzios2011computing}, Co-Comparability graphs in $\mathcal{O}(n^4)$ time~\cite{mertzios2012simple}, and Ptolemaic graphs in $\mathcal{O}(n^5)$ time~\cite{takahara2008longest}.

The LSP problem on general graphs has been intensively studied by many. One notable approach is dynamic programming using graph partitioning~\cite{balyo2017optimal}, including parallelization~\cite{fieger2019finding}. Another approach uses constraint programming, with both an exact algorithm and a tabu local-search algorithm: this is more successful in niche groups of graphs~\cite{pham2012solving}.

Approximations and heuristics for LSP have also been a big consideration. Approximation has been applied to specific graph groups without polynomial time solutions, such as grid graphs~\cite{zhang2011approximating}, (approximated in $O({n^2})$ time), and also to more general cases. Examples of approximation algorithms include genetic algorithms~\cite{mathew2012genetic, portugal2010study, scholvin1999approximating}, a color-coding~\cite{alon1995color} inspired approximation~\cite{scutella2003approximation}, a simulated annealing algorithm~\cite{scholvin1999approximating}, and a tabu-search algorithm~\cite{scholvin1999approximating}.

Two heuristic approaches similar to ours were a graph pruning heuristic and a greedy variation heuristic. A permissible grid-graph pruning heuristic was used with A* and Depth-First Branch-and-Bound complete search algorithms to find the LSP~\cite{cohen2020solving}. A greedy variation heuristic called the \textit{k}-step Greedy Lookahead employed a method of finding partial paths by looking \textit{k} vertices ahead~\cite{scholvin1999approximating}.

\section{Heuristics}

We developed several heuristic approximations to LSP for undirected unit-weighted connected graphs. These heuristics employed past techniques, such as the greedy or pruning algorithms, but utilized different graph characteristics. In the process of applying and testing our heuristics, we confirmed properties of the LSP problem introduced by previous works. We also discovered results to utilizing certain graph characteristics that could be helpful for future work.

\subsection{Greedy Heuristics}

The first group of heuristics that were explored were ones based on the classic greedy algorithm. As these algorithms depend on making the ``best" decision at their current location in the problem, or in this case, the graph. In order to utilize this principle, there needed to be a graph characteristic that was identifiable and able to be recalculated on a local scale. This led us to the graph characteristic of vertex neighbor counts. A vertex neighbor count is the number of vertices adjacent to the vertex whose neighbor count is being calculated. This was a feature of the graph that could be recomputed every step. 

The greedy heuristic utilizing the graph's vertex neighbor count feature, or the Greedy Neighbor heuristic, found the longest simple path in a graph by starting at each vertex. It would then traverse the graph by choosing adjacent vertices with the least available neighbors until there were no options left. Each step in the traversal required a recalculation of the available vertices along with their neighbor count. Each starting node would eventually end up with a greedy traversal of the graph, which was then used to calculate the greedy path from each vertex. Finally, the longest greedy path was output as the heuristics solution to the LSP problem in the given graph.

This heuristic was based on the options for the next vertex in traversing the graph. The heuristic would prioritize visiting vertices with fewer neighbors and thus a lower number of ``options" by which it could be reached. Consequentially, vertices with more neighbors were visited later, as there were more ``options" to get to them. The problem with this heuristic was that it was often in a position where two or more vertices adjacent to the current vertex had the same number of available neighbors, putting the heuristic at a crossroads of tie breaking. In our first iteration of the Greedy Neighbor heuristic, the vertex with a lower ID was chosen. While this sometimes was inconsequential, because in many cases both paths led to longest paths being found, there were also graphs where choosing the lower node ID led to a shorter path length than the desired LSP. This behavior was most noticeable in larger and sparse graphs with seven or more vertices. There needed to be a tiebreaker that could pick the correct choice instead of letting chance decide. 

The second version of the Greedy Neighbor heuristic involved a Depth-First-Search (DFS) that acted as the tiebreaker when more than one adjacent vertex had the most neighbors. This DFS was a specialized version that traversed the remaining available vertices in the graph. It prioritized visiting vertices with lower IDs (instead of randomly deciding the next vertex). For each of the tied adjacent vertices, it created a tree graph with the root being the starting DFS vertex. For each vertex that had tied with having the most neighbors, we executed the specialized DFS to create post-DFS trees. The internal path length is the sum the depth (distance from root) of all nodes. The internal path length (ipl) of each post-DFS tree was calculated and the one with the highest was chose as the next vertex to visit in the greedy traversal. 

\subsection{Graph Centrality, Periphery, and Pruning}
The second group of heuristics based on the centrality of the vertices. The definition of three key terms representing graph and vertex centrality are as follows: 

\begin{enumerate}
    \item \textbf{Vertex Periphery}: For any vertex \textit{A}, the vertex periphery (VP) is the longest shortest path from \textit{A} to any other vertex. The lower the vertex periphery of \textit{A}, the more central \textit{A} is.
    \item \textbf{Total Vertex Periphery}:  For any vertex \textit{A}, the total vertex periphery (TVP) is the sum of all shortest paths from \textit{A} to every other vertex. The lower the total vertex periphery of \textit{A}, the more central \textit{A} is. Figure~\ref[fig:GraphTVPGradient]
gives a visual illustration of TVP.
    \item \textbf{Graph Periphery}: For any graph \textit{G}, the graph periphery (GP) is the sum of all total vertex periphery in \textit{G}.
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{GraphTVPGradientsExamples.jpg}
    \caption{Example Graphs With Gradient Representation of Total Vertex Periphery}
    \label{fig:GraphTVPGradient}
\end{figure}

All graph centrality heuristics were based on the idea that given a graph \textit{G} with \textit{n} vertices and \textit{m} edges, if you cut specific \(m - (n - 1)\) edges, the graph will then be pruned into a tree, \textit{T}, whose longest path corresponds to the longest path in. The longest path of \textit{T} could then be found in linear time with Dijkstra's Dangle algorithm~\cite{club2002computing}.


The first graph centrality heuristic was one the made use of the total vertex periphery values. Named the Prune Central Edges heuristic, it relied on the assumption that the edges connecting vertices with lower TVP (meaning that they were more central edges) were unnecessary in the LSP of the graph. However, that proved to be an incorrect assumption because during testing, it was found that in certain instances, the edge connecting vertices with the lowest TVP, was utilized in the longest simple path.

The second graph centrality heuristic also made use of the total vertex periphery values. The Stretch Lowest TVP, this heuristic worked by choosing a vertex \textit{V} with the lowest TVP that had available edges that could be removed without disconnecting the graph. Next, the heuristic would find and cut the edge connecting to \textit{V} that, when removed, would increase the TVP of \textit{V} the most. This heuristic operated under the idea that the optimal tree---containing the longest path---would have the highest possible graph periphery. By removing edges from the vertices with low TVP, the heuristic would be increasing the TVP of the vertices and stretching the GP of the graph.

Through our testing, it was found that in certain graphs, the edges that would increase the TVP of a vertex were edges that were a crucial part of the graph's LSP. As a result, the principle that this exact heuristic followed was not the correct way to go about cutting the graph into a tree.

The third graph centrality heuristic made use of the graph periphery (GP). The Stretch Total Graph heuristic operated by finding looping through all removable edges (ones that did not create discontinuities in the graph) and finding the one that brought about the largest increase in the GP when removed. Similar to the Strech Lowest TVP heuristic, the Stretch Total Graph heuristic also worked to remove edges the lowered the graph periphery and to stretch the graph out to its widest possible tree. 

Similar to the Stretch Lowest TVP heuristic, it was revealed that there were graphs that did not apply to the principle used in the Stretch Total Graph heuristic. There were certain graphs where the edge that increased the GP the most were part of the longest simple path. Other graphs had edges that increased the GP the same. With no tiebreaker method, the edge with lower vertex IDs would be chosen to be removed. As such, there were graphs where necessary edges were removed because of ties between edges.

\section{Experimental Results}

As we designed our heuristics, we experimented with prototype implementations. We eventually constructed a benchmark suite for a more thorough evaluation.

\subsection{Experiment Setup}

In order to implement our heuristics, we utilized the Python programming language (version 3.10.4) and its \texttt{igraph} package. The \texttt{igraph} package contains an extensive array of functions and variable types fit for quick and efficient manipulation as well as useful graph visualization tools. We utilized igraph's ability to quickly add and remove edges and vertices, as well as its functions for plotting graphs and returning important graph characteristics such number of edges, vertices, or a vertex's neighbors. The package also included functions such as get\_simple\_paths or shortest\_paths that made the translation of heuristics from idea to code a straightforward process.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{examplegraph.png}
    \caption{Example Graph, Drawn by Python-igraph}
    \label{fig:ExampleGraph}
\end{figure}

The graphs that we chose to work with were the dots and lines graphs such as the graph in Figure 1. Working with graphs that were visualized this way allowed there to be both different implementations of past heuristics like the greedy heuristic and new characteristics of graphs to be revealed.

\subsection{Experimental Approach}

The first step to implementing heuristics was the proof of concept. By looking at characteristics of a graph, we were able to deduce the ones that may be of use in a heuristic. Characteristics such as vertex neighbor count, diameter of the graph, and vertex centrality were all examples of graph characteristics that were involved in one or more heuristics. We often used graph features for inspiration when pondering possible heuristics.

When heuristic ideas revealed themselves to be feasible and capable of attaining accurate longest simple paths, a general or multiple versions pseudo code was written to be used in the second step: Python implementation. This was where the ideas were implemented into heuristics compatible with \texttt{igraph} for testing. 

\subsection{Random Graph Generation}
The random graphs for visualization and benchmarking were created through a randomization process called Tree-Base-Graph-Gen. This algorithm, given a \textit{n} vertices and \textit{m} edges, creates a random, undirected, connected graph by creating a tree with all \textit{n} vertices and \(n-1\) edges. The remaining \(m - (n - 1)\) required edges are then added randomly throughout the graph.

This random graph generation, however, is not truly random. Due to the way that the algorithm chooses ``random" target edges during the base-tree creation phase, certain graph shapes are more likely to be built than others. 

\subsection{Benchmarking Methods}
For the testing and benchmarking of our heuristics, we created three tests to measure crucial areas of the Longest Simple Path Problem: accuracy, error, and runtime. For consistency, the graphs used throughout all tests were the same graphs. The tests were as follows:

\begin{enumerate}
    \item \textbf{Accuracy:} The percentage of graphs that a given heuristic gets the exact longest simple paths for.
    \item \textbf{Error:} The average difference between the actual longest simple path and longest simple path found by a given heuristic.
    \item \textbf{Runtime:} The time of average execution time of a given heuristic over a group of graphs.
\end{enumerate}

\subsection{Experimental Results}
The accuracy benchmark confirmed the findings of several past experiments. All heuristics were seen to have a ``canyon" behavior. At any vertex count, as the edge count increases, the accuracy of the heuristics decrease to a lower bound, then increases after hitting the lower bound. In other words, the LSP of tree graphs, and dense graphs were a accurately found by the heuristics, while the sparse and non-tree graphs were the difficult graphs to find a correct LSP for. This confirms the claims of other studies that have said the sparse graphs to be the real challenge of the LSP problem. 

In addition, the accuracy tests also reveal that both variants of the greedy algorithm, with and without the depth-first-search tiebreaker, were both guaranteed to get the correct LSP in dense graphs, which also confirms previous findings. For graph pruning graphs, the accuracy shown was worse than the greedy heuristics, signalling that, as stand-alone heuristics, they are not as effective as greedy heuristics. However, it is possible that implementing them in tandem with something like A* or local search could produce desirable results.

The runtime tests we administered showed that in comparison to the naive, brute-force solution, all heuristic runtimes grew at a slower pace. The brute-force solution has a clear exponential growth in runtime as the number of edges increases, while the heuristics have runtimes that increase more gradually. The one exception to this behavior was the heuristic that stretched the graph periphery. Because of its need to loop through all edges each time, in sparse graphs, it has a slower runtime than the brute-force algorithm. Furthermore, as the number of vertices increases, its runtime also increases by a larger degree than other heuristics. Despite its relative inefficiencies, the stretching graph periphery heuristic is still more efficient than the naive solution.

\section{Conclusions}

In this paper, we covered the difficulties of the longest simple path problems as well as the directions in which we explored possible implementations of heuristics for more efficient solutions or approximations to finding the LSP. Through our experimentation, we confirmed past findings about the greedy heuristics abilities to solve the LSP problem on dense graphs and difficulties that sparse graphs provide to the problem. We also discussed the reasoning behind the various graph pruning heuristics. Although, they may not be as accurate as the greedy heuristics, they showed potential to be combined with heuristic searches such as A* or local search for possible heuristics in future work.

\section*{Acknowledgements}

\bibliographystyle{plain}
\bibliography{References.bib}

\end{document}
